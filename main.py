import streamlit as st
import arxiv
import datetime
from datetime import timedelta
import pandas as pd

# ==========================================
# é¡µé¢é…ç½®
# ==========================================
st.set_page_config(
    page_title="ArXiv è®ºæ–‡å°åŠ©æ‰‹",
    page_icon="ğŸ“‘",
    layout="wide"
)

# ==========================================
# ä¾§è¾¹æ ï¼šæœç´¢æ¡ä»¶è®¾ç½®
# ==========================================
st.sidebar.header("ğŸ” æœç´¢è®¾ç½®")

# 1. å…³é”®è¯è¾“å…¥
keywords = st.sidebar.text_input("è¯·è¾“å…¥å…³é”®è¯ (æ”¯æŒ AND, OR)", value="LLM AND Reasoning")

# 2. å®½æ³›é¢†åŸŸé€‰æ‹© (è§£å†³åˆ†ç±»ä¸å‡†çš„é—®é¢˜)
category_bundle = st.sidebar.selectbox(
    "é€‰æ‹©æœç´¢èŒƒå›´ (é˜²æ­¢æ¼æ‰è·¨é¢†åŸŸè®ºæ–‡)",
    options=["AI & CS (æ™ºèƒ½ç»„åˆ)", "Computer Science (ä»…CS)", "Physics", "Math", "All Fields (å…¨åº“)"],
    index=0
)

# å®šä¹‰é¢†åŸŸæŸ¥è¯¢è¯­å¥
category_queries = {
    "AI & CS (æ™ºèƒ½ç»„åˆ)": 'cat:cs.CV OR cat:cs.CL OR cat:cs.LG OR cat:cs.AI OR cat:stat.ML OR cat:eess.IV OR cat:cs.RO',
    "Computer Science (ä»…CS)": 'cat:cs.*',
    "Physics": 'cat:astro-ph OR cat:cond-mat OR cat:gr-qc OR cat:hep-ex OR cat:hep-lat OR cat:hep-ph OR cat:hep-th OR cat:math-ph OR cat:nlin OR cat:nucl-ex OR cat:nucl-th OR cat:physics OR cat:quant-ph',
    "Math": 'cat:math.*',
    "All Fields (å…¨åº“)": 'all'
}

# 3. æ—¶é—´èŒƒå›´é€‰æ‹©
days_back = st.sidebar.slider("æœç´¢è¿‡å»å¤šå°‘å¤©?", min_value=1, max_value=365, value=7)
today = datetime.datetime.now(datetime.timezone.utc)
start_date = today - timedelta(days=days_back)

# 4. æœ€å¤§ç»“æœæ•°
max_results = st.sidebar.number_input("æœ€å¤§ç»“æœæ•°é‡", min_value=5, max_value=100, value=20)

# 5. æ’åºæ–¹å¼
sort_by_options = {
    "å‘å¸ƒæ—¶é—´ (æœ€æ–°)": arxiv.SortCriterion.SubmittedDate,
    "ç›¸å…³æ€§": arxiv.SortCriterion.Relevance,
    "æœ€åæ›´æ–°æ—¶é—´": arxiv.SortCriterion.LastUpdatedDate
}
sort_text = st.sidebar.selectbox("æ’åºæ–¹å¼", list(sort_by_options.keys()))
sort_criterion = sort_by_options[sort_text]


# ==========================================
# æ ¸å¿ƒé€»è¾‘ï¼šæ„å»ºæŸ¥è¯¢å¹¶è·å–æ•°æ®
# ==========================================

# æ„å»º ArXiv æŸ¥è¯¢è¯­å¥
def build_query(keywords, category_bundle_key):
    cat_query = category_queries[category_bundle_key]
    
    if category_bundle_key == "All Fields (å…¨åº“)":
        # å…¨åº“æœç´¢ä¸éœ€è¦åŠ  cat: å‰ç¼€é€»è¾‘
        final_query = keywords
    else:
        # å…³é”®è¯ + é¢†åŸŸé™åˆ¶
        final_query = f'({keywords}) AND ({cat_query})'
    
    return final_query


# è·å–æ•°æ®çš„å‡½æ•° (å¸¦ç¼“å­˜ï¼Œé˜²æ­¢é‡å¤è¯·æ±‚)
# @st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶
# def fetch_arxiv_papers(query, max_results, sort_criterion):
#     client = arxiv.Client()
#     search = arxiv.Search(
#         query=query,
#         max_results=max_results,
#         sort_by=sort_criterion,
#         sort_order=arxiv.SortOrder.Descending
#     )
#
#     results = []
#     for result in client.results(search):
#         # äºŒæ¬¡è¿‡æ»¤ï¼šç¡®ä¿æ—¶é—´ç¬¦åˆï¼ˆAPIçš„sortBy dateæœ‰æ—¶å€™ä¸ç»å¯¹ç²¾ç¡®è¿‡æ»¤ï¼Œæ‰‹åŠ¨å¡ä¸€ä¸‹æ›´å‡†ï¼‰
#         # æ³¨æ„ï¼šRelevance æ’åºæ—¶ï¼ŒAPI å¯èƒ½ä¼šè¿”å›æ—§è®ºæ–‡ï¼Œè¿™é‡Œæ ¹æ®ç”¨æˆ·éœ€æ±‚å†³å®šæ˜¯å¦ä¸¥æ ¼æŒ‰æ—¶é—´è¿‡æ»¤
#         # å¦‚æœç”¨æˆ·é€‰çš„æ˜¯â€œæŒ‰æ—¶é—´æ’åºâ€ï¼Œé€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è¿‡æ»¤å¤ªå¤šï¼Œä½†ä¸ºäº†ä¿é™©èµ·è§ï¼š
#         if sort_criterion == arxiv.SortCriterion.SubmittedDate:
#             if result.published < start_date:
#                 continue
#
#         results.append(result)
#     return results


from tenacity import retry, stop_after_attempt, wait_fixed


# ==========================================
# ä¼˜åŒ–åçš„æ ¸å¿ƒæŠ“å–å‡½æ•°
# ==========================================

@st.cache_data(ttl=3600)
# @retry(stop=stop_after_attempt(3), wait=wait_fixed(2)) # å¦‚æœæ²¡è£… tenacity å¯ä»¥æ³¨é‡Šæ‰è¿™è¡Œ
def fetch_arxiv_papers(query, days_back, max_display_results):
    """
    ç­–ç•¥ï¼šå®½è¿›ä¸¥å‡ºã€‚
    1. å‘ API è¯·æ±‚æ¯”ç”¨æˆ·éœ€è¦å¤š 3-5 å€çš„æ•°æ® (buffer)ã€‚
    2. å¼ºåˆ¶æŒ‰ Relevance (ç›¸å…³æ€§) æ’åºï¼Œä¿è¯æœåˆ°çš„éƒ½æ˜¯åŒ¹é…åº¦é«˜çš„ã€‚
    3. åœ¨æœ¬åœ°è¿›è¡Œâ€œæ—¶é—´æ¸…æ´—â€ï¼Œå‰”é™¤è€æ–‡ç« ã€‚
    4. (å¯é€‰) è¿›è¡Œâ€œæ ‡é¢˜ä¼˜å…ˆâ€é‡æ’åºã€‚
    """
    
    # è®¡ç®—æˆªæ­¢æ—¥æœŸ
    today = datetime.datetime.now(datetime.timezone.utc)
    start_date = today - timedelta(days=days_back)
    
    # 1. è®¾å®šæŠ“å–ç¼“å†²åŒº (Buffer)
    # å¦‚æœç”¨æˆ·è¦çœ‹ 20 ç¯‡ï¼Œæˆ‘ä»¬å» API æŠ“ 100 ç¯‡ï¼Œç¡®ä¿è¿‡æ»¤æ‰è€æ–‡ç« åè¿˜æœ‰å‰©ä¸‹çš„
    fetch_limit = max_display_results * 5
    
    client = arxiv.Client()
    search = arxiv.Search(
        query=query,
        max_results=fetch_limit,
        sort_by=arxiv.SortCriterion.Relevance,  # å¼ºåˆ¶æŒ‰ç›¸å…³æ€§ï¼Œè§£å†³â€œä¸å¤Ÿmatchâ€çš„é—®é¢˜
        sort_order=arxiv.SortOrder.Descending
    )
    
    filtered_results = []
    
    # 2. éå†å¹¶æ¸…æ´—æ•°æ®
    for result in client.results(search):
        # [æ—¶é—´è¿‡æ»¤å™¨]
        # å¦‚æœæ–‡ç« å‘å¸ƒæ—¶é—´ æ—©äº æˆ‘ä»¬è®¾å®šçš„èµ·å§‹æ—¶é—´ï¼Œä¸¢å¼ƒ
        if result.published < start_date:
            continue
        
        # [æœ¬åœ°åŠ æƒé€»è¾‘ - å¯é€‰]
        # æˆ‘ä»¬å¯ä»¥ç»™ result å¯¹è±¡åŠ ä¸€ä¸ªè‡ªå®šä¹‰å±æ€§ score
        # ç®€å•é€»è¾‘ï¼šæ ‡é¢˜é‡Œæœ‰å…³é”®è¯çš„æ’åœ¨å‰é¢
        # æ³¨æ„ï¼šè¿™é‡Œä»…ä½œç®€å•å¤„ç†ï¼Œä¿ç•™åŸé¡ºåºï¼ˆå› ä¸ºArXivå·²ç»ç®—è¿‡ç›¸å…³æ€§äº†ï¼‰ï¼Œä½†æŠŠæ—¶é—´ç¬¦åˆçš„ç•™ä¸‹æ¥
        
        filtered_results.append(result)
        
        # å¦‚æœè¿‡æ»¤åçš„æ•°é‡å·²ç»å¤Ÿäº†ç”¨æˆ·è¦çš„æ•°é‡ï¼Œå°±åœæ­¢
        if len(filtered_results) >= max_display_results:
            break
    
    return filtered_results


# ==========================================
# ä¸»ç•Œé¢å±•ç¤º
# ==========================================
st.title("ğŸ“‘ ArXiv Paper Daily Tracker")
st.markdown(f"**å½“å‰æœç´¢:** `{keywords}` | **èŒƒå›´:** `{category_bundle}` | **è¿‡å»:** `{days_back} å¤©`")

if st.button("å¼€å§‹æŠ“å–", type="primary"):
    if not keywords:
        st.warning("è¯·è¾“å…¥å…³é”®è¯ï¼")
    else:
        with st.spinner('æ­£åœ¨è¿æ¥ ArXiv æ•°æ®åº“...'):
            query_string = build_query(keywords, category_bundle)
            try:
                # papers = fetch_arxiv_papers(query_string, max_results, sort_criterion)
                papers = fetch_arxiv_papers(query_string, days_back, max_results)
                
                if not papers:
                    st.info("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡ï¼Œè¯·å°è¯•æ”¾å®½æ—¶é—´æˆ–æ›´æ¢å…³é”®è¯ã€‚")
                else:
                    st.success(f"æˆåŠŸæ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡ï¼")
                    st.divider()
                    
                    # ç”¨äºæ”¶é›†å¯¼å‡ºæ•°æ®çš„åˆ—è¡¨
                    export_text = f"# ArXiv Papers: {keywords}\nDate: {datetime.datetime.now().strftime('%Y-%m-%d')}\n\n"
                    
                    for i, paper in enumerate(papers):
                        # æ ¼å¼åŒ–ä½œè€… (åªæ˜¾ç¤ºå‰3ä½)
                        authors = [a.name for a in paper.authors]
                        author_str = ", ".join(authors[:3]) + (" et al." if len(authors) > 3 else "")
                        
                        # è®ºæ–‡å¡ç‰‡
                        with st.container():
                            col1, col2 = st.columns([0.85, 0.15])
                            with col1:
                                st.subheader(f"{i + 1}. {paper.title}")
                                st.markdown(
                                    f"**âœï¸ ä½œè€…:** {author_str} | **ğŸ“… å‘å¸ƒ:** {paper.published.strftime('%Y-%m-%d')}")
                                st.markdown(f"**ğŸ”— é“¾æ¥:** [PDF]({paper.pdf_url}) | [ArXiv Page]({paper.entry_id})")
                            
                            # æ‘˜è¦æŠ˜å åŒºåŸŸ
                            with st.expander("ğŸ“– æŸ¥çœ‹æ‘˜è¦ (Abstract)"):
                                st.write(paper.summary)
                                st.caption(f"Categories: {', '.join(paper.categories)}")
                            
                            st.divider()
                        
                        # å‡†å¤‡å¯¼å‡ºæ–‡æœ¬
                        export_text += f"### {paper.title}\n- **Authors:** {author_str}\n- **Link:** {paper.entry_id}\n- **Summary:** {paper.summary}\n\n---\n\n"
                    
                    # å¯¼å‡ºåŒºåŸŸ
                    st.header("ğŸ“¤ å¯¼å‡ºç»“æœ")
                    st.download_button(
                        label="ä¸‹è½½ Markdown æŠ¥å‘Š",
                        data=export_text,
                        file_name=f"arxiv_papers_{datetime.datetime.now().strftime('%Y%m%d')}.md",
                        mime="text/markdown"
                    )
            
            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯: {e}")

else:
    st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è®¾ç½®æœç´¢æ¡ä»¶ï¼Œç„¶åç‚¹å‡»â€œå¼€å§‹æŠ“å–â€")