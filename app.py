import streamlit as st
import datetime
import os
import utils
import arxiv_api
import paper_reader
import ai_agent
import storage

# ==========================================
# é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="ArXiv è®ºæ–‡å°åŠ©æ‰‹", page_icon="ğŸ“‘", layout="wide")

# ==========================================
# ä¾§è¾¹æ ï¼šå…¨å±€è®¾ç½® & æ¨¡å¼åˆ‡æ¢
# ==========================================
mode = st.sidebar.radio("åŠŸèƒ½æ¨¡å¼", ["ğŸ” è®ºæ–‡æœç´¢", "â­ æˆ‘çš„æ”¶è—"])
st.sidebar.divider()

# åˆå§‹åŒ– Session State
if "papers" not in st.session_state:
    st.session_state.papers = []
if "summaries" not in st.session_state:
    st.session_state.summaries = {}


# ==========================================
# è¾…åŠ©å‡½æ•°ï¼šç»Ÿä¸€æ¸²æŸ“å¡ç‰‡
# ==========================================
def render_paper_card(paper, is_favorite_mode=False, api_key=None, base_url=None, model_name=None):
    """
    æ¸²æŸ“å•ä¸ªè®ºæ–‡å¡ç‰‡ï¼Œå¤ç”¨äºæœç´¢é¡µå’Œæ”¶è—é¡µã€‚
    """
    # ç»Ÿä¸€æ•°æ®æ ¼å¼
    if isinstance(paper, dict):
        title = paper['title']
        entry_id = paper['entry_id']
        pdf_url = paper['pdf_url']
        published_date = paper['published']
        authors_list = paper['authors']
        summary_text = paper['summary']
        # è·å–æ ‡ç­¾å’Œç¬”è®° (ä»…æ”¶è—æ¨¡å¼ä¸‹æœ‰æ•ˆ)
        current_tags = paper.get('tags', [])
        current_notes = paper.get('notes', "")
    else:
        title = paper.title
        entry_id = paper.entry_id
        pdf_url = paper.pdf_url
        published_date = paper.published.strftime('%Y-%m-%d')
        authors_list = [a.name for a in paper.authors]
        summary_text = paper.summary
        current_tags = []
        current_notes = ""
    
    # --- UI æ¸²æŸ“ ---
    with st.container():
        col1, col2 = st.columns([0.85, 0.15])
        
        with col1:
            st.subheader(title)
            
            # [æ–°å¢] å¦‚æœæœ‰æ ‡ç­¾ï¼Œåœ¨æ ‡é¢˜ä¸‹æ–¹æ˜¾ç¤º
            if is_favorite_mode and current_tags:
                # ä½¿ç”¨ Markdown æ¨¡æ‹Ÿ Tag æ ·å¼
                tag_str = " ".join([f"`{t}`" for t in current_tags])
                st.markdown(f"ğŸ·ï¸ {tag_str}")
            
            author_str = ", ".join(authors_list[:3]) + (" et al." if len(authors_list) > 3 else "")
            html_link = f"https://arxiv.org/html/{entry_id.split('/')[-1]}"
            st.markdown(f"**âœï¸ ä½œè€…:** {author_str} | **ğŸ“… å‘å¸ƒ:** {published_date}")
            st.markdown(f"[HTML é˜…è¯»]({html_link}) | [PDF ä¸‹è½½]({pdf_url}) | [ArXiv é¡µé¢]({entry_id})")
        
        with col2:
            # 1. AI è§£è¯»æŒ‰é’®
            ai_btn_key = f"ai_{entry_id}_{'fav' if is_favorite_mode else 'search'}"
            if st.button("ğŸ¤– AI è§£è¯»", key=ai_btn_key):
                status = st.empty()
                status.info("â³ è·å–æ­£æ–‡...")
                content, src = paper_reader.get_paper_content(entry_id, pdf_url)
                if content.startswith("Error"):
                    status.error("âŒ è·å–å¤±è´¥")
                else:
                    status.info(f"âœ… æ­£åœ¨é˜…è¯» ({src})...")
                    summary = ai_agent.get_ai_summary(content, title, api_key, base_url, model_name)
                    
                    st.session_state.summaries[entry_id] = summary
                    storage.update_favorite_summary(entry_id, summary)
                    status.empty()
            
            # 2. æ”¶è—/ç§»é™¤æŒ‰é’®
            if is_favorite_mode:
                if st.button("âŒ ç§»é™¤", key=f"del_{entry_id}"):
                    storage.remove_favorite(entry_id)
            else:
                if st.button("â¤ï¸ æ”¶è—", key=f"fav_{entry_id}"):
                    current_ai_summary = st.session_state.summaries.get(entry_id)
                    storage.save_favorite(paper, ai_summary=current_ai_summary)
        
        # å±•ç¤º AI ç»“æœ
        if entry_id in st.session_state.summaries:
            with st.expander("ğŸ“ AI æ·±åº¦åˆ†æ", expanded=True):
                st.info(st.session_state.summaries[entry_id])
        
        # [æ–°å¢] æ ‡ç­¾ä¸ç¬”è®°ç¼–è¾‘åŒº (ä»…åœ¨æ”¶è—æ¨¡å¼æ˜¾ç¤º)
        if is_favorite_mode:
            with st.expander("ğŸ·ï¸ ç¼–è¾‘æ ‡ç­¾ & ğŸ“ ä¸ªäººç¬”è®°"):
                with st.form(key=f"form_{entry_id}"):
                    # æ ‡ç­¾è¾“å…¥
                    tags_str = st.text_input("æ ‡ç­¾ (ç”¨é€—å·åˆ†éš”, ä¾‹å¦‚: LLM, Economics)", value=", ".join(current_tags))
                    # ç¬”è®°è¾“å…¥
                    notes_content = st.text_area("ä¸ªäººç¬”è®° / å¤‡å¿˜å½•", value=current_notes, height=100)
                    
                    if st.form_submit_button("ğŸ’¾ ä¿å­˜æ›´æ”¹"):
                        # å¤„ç†æ ‡ç­¾å­—ç¬¦ä¸² -> åˆ—è¡¨
                        new_tags = [t.strip() for t in tags_str.split(",") if t.strip()]
                        storage.update_favorite_details(entry_id, new_tags, notes_content)
                        st.rerun()
        
        with st.expander("ğŸ“– æ‘˜è¦ (Abstract)"):
            st.write(summary_text)
        
        st.divider()


# ==========================================
# é¡µé¢ 1: ğŸ” è®ºæ–‡æœç´¢
# ==========================================
if mode == "ğŸ” è®ºæ–‡æœç´¢":
    st.sidebar.header("ğŸ” æœç´¢è®¾ç½®")
    
    search_presets = {
        "1. AI + Economics":
            '(Economic OR Economics OR Finance OR Financial OR Market OR "Behavioral Economics") AND (LLM OR "Large Language Model" OR RL OR "Reinforcement Learning")',
        "2. Agents (Multi-Agent / LLM Agent)":
            '("Multi-Agent" OR "Multiagent" OR "Autonomous Agent" OR "LLM Agent" OR "Language Agent" OR "RL Agent" OR "Agentic") AND (LLM OR "Large Language Model" OR RL OR "Reinforcement Learning")',
        "3. World Models":
            '"World Model" OR "World Models" OR "Generative World Model" OR "Model-Based RL" OR MBRL OR "Predictive Model"',
        "4. Evolution":
            'agent AND LLM AND (evolution OR evole)',
        "5. è‡ªå®šä¹‰ (ç©ºç™½)": ""
    }
    selected_preset_key = st.sidebar.selectbox("å¿«é€Ÿé€‰æ‹©é¢„è®¾", options=list(search_presets.keys()), index=0)
    default_keyword = search_presets[selected_preset_key]
    
    keywords = st.sidebar.text_input("å…³é”®è¯", value=default_keyword)
    category_bundle = st.sidebar.selectbox("é€‰æ‹©æœç´¢èŒƒå›´", options=list(utils.CATEGORY_QUERIES.keys()), index=0)
    days_back = st.sidebar.slider("æœç´¢è¿‡å»å¤šå°‘å¤©?", min_value=1, max_value=365, value=7)
    max_results = st.sidebar.number_input("æœ€å¤§ç»“æœæ•°é‡", min_value=5, max_value=100, value=20)
    
    st.sidebar.divider()
    st.sidebar.header("ğŸ¤– AI è®¾ç½®")
    env_api_key = os.getenv("OPENAI_API_KEY", "")
    api_key = st.sidebar.text_input("API Key", value=env_api_key, type="password")
    base_url = st.sidebar.text_input("Base URL", value="https://api.openai.com/v1")
    model_name = st.sidebar.text_input("æ¨¡å‹åç§°", value="gpt-4o-mini")
    
    st.title("ğŸ“‘ ArXiv Paper Daily Tracker")
    st.caption(f"å½“å‰æ¨¡å¼: {category_bundle} | çª—å£: {days_back}å¤© | å…³é”®è¯ï¼š{keywords}")
    
    if st.button("å¼€å§‹æŠ“å–", type="primary"):
        if not keywords:
            st.warning("è¯·è¾“å…¥å…³é”®è¯ï¼")
        else:
            with st.spinner('æ­£åœ¨è¿æ¥ ArXiv æ•°æ®åº“...'):
                query_string = utils.build_query(keywords, category_bundle)
                papers = arxiv_api.fetch_arxiv_papers(query_string, days_back, max_results)
                
                if not papers:
                    st.info("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡ï¼Œè¯·å°è¯•æ”¾å®½æ—¶é—´æˆ–æ›´æ¢å…³é”®è¯ã€‚")
                else:
                    st.session_state.papers = papers
                    st.session_state.summaries = {}
                    st.success(f"æˆåŠŸæ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡ï¼")
    
    if st.session_state.papers:
        st.divider()
        for paper in st.session_state.papers:
            render_paper_card(paper, is_favorite_mode=False, api_key=api_key, base_url=base_url, model_name=model_name)
        
        st.header("ğŸ“¤ å¯¼å‡ºç»“æœ")
        if st.button("ç”Ÿæˆ Markdown æŠ¥å‘Š"):
            export_text = utils.generate_export_text(st.session_state.papers, keywords)
            st.download_button("ä¸‹è½½æ–‡ä»¶", export_text, f"arxiv_report_{datetime.date.today()}.md")

# ==========================================
# é¡µé¢ 2: â­ æˆ‘çš„æ”¶è—
# ==========================================
elif mode == "â­ æˆ‘çš„æ”¶è—":
    st.title("â­ æˆ‘çš„è®ºæ–‡æ”¶è—å¤¹")
    
    st.sidebar.header("ğŸ¤– AI è®¾ç½®")
    env_api_key = os.getenv("OPENAI_API_KEY", "")
    api_key = st.sidebar.text_input("API Key", value=env_api_key, type="password")
    base_url = st.sidebar.text_input("Base URL", value="https://api.openai.com/v1")
    model_name = st.sidebar.text_input("æ¨¡å‹åç§°", value="gpt-4o-mini")
    
    # 1. åŠ è½½æ‰€æœ‰æ”¶è—
    favorites = storage.load_favorites()
    
    if not favorites:
        st.info("è¿˜æ²¡æœ‰æ”¶è—ä»»ä½•è®ºæ–‡ã€‚å»æœç´¢é¡µç‚¹ä¸ª â¤ï¸ å§ï¼")
    else:
        # [æ–°å¢] é¡¶éƒ¨æ ‡ç­¾ç­›é€‰å™¨
        all_tags = storage.get_all_unique_tags()
        if all_tags:
            selected_tags = st.multiselect("ğŸ·ï¸ æŒ‰æ ‡ç­¾ç­›é€‰ (æ˜¾ç¤ºæ»¡è¶³ä»»ä¸€æ ‡ç­¾çš„è®ºæ–‡)", options=all_tags)
        else:
            selected_tags = []
        
        # æ‰§è¡Œç­›é€‰é€»è¾‘
        if selected_tags:
            # åªè¦åŒ…å«é€‰ä¸­çš„ä»»æ„ä¸€ä¸ªæ ‡ç­¾ï¼Œå°±æ˜¾ç¤º (OR é€»è¾‘)
            display_papers = [
                p for p in favorites
                if any(tag in p.get('tags', []) for tag in selected_tags)
            ]
        else:
            display_papers = favorites
        
        st.markdown(f"æ˜¾ç¤º **{len(display_papers)}** ç¯‡è®ºæ–‡ (æ€»æ”¶è—: {len(favorites)})")
        st.divider()
        
        for paper_dict in display_papers:
            # è‡ªåŠ¨åŠ è½½ AI è§£è¯»
            entry_id = paper_dict['entry_id']
            if paper_dict.get('ai_summary') and entry_id not in st.session_state.summaries:
                st.session_state.summaries[entry_id] = paper_dict['ai_summary']
            
            render_paper_card(paper_dict, is_favorite_mode=True, api_key=api_key, base_url=base_url,
                              model_name=model_name)