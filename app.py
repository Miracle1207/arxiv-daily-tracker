import streamlit as st
import datetime
import os
# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import utils
import arxiv_api
import paper_reader
import ai_agent
import storage  # <--- ä¿æŒå¯¼å…¥å­˜å‚¨æ¨¡å—

# ==========================================
# é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="ArXiv è®ºæ–‡å°åŠ©æ‰‹", page_icon="ğŸ“‘", layout="wide")

# ==========================================
# ä¾§è¾¹æ ï¼šå…¨å±€è®¾ç½® & æ¨¡å¼åˆ‡æ¢
# ==========================================
# æ¨¡å¼åˆ‡æ¢æ”¾åœ¨æœ€ä¸Šé¢ï¼Œæ–¹ä¾¿åˆ‡æ¢
mode = st.sidebar.radio("åŠŸèƒ½æ¨¡å¼", ["ğŸ” è®ºæ–‡æœç´¢", "â­ æˆ‘çš„æ”¶è—"])
st.sidebar.divider()

# åˆå§‹åŒ– Session State
if "papers" not in st.session_state:
    st.session_state.papers = []
if "summaries" not in st.session_state:
    st.session_state.summaries = {}


# ==========================================
# è¾…åŠ©å‡½æ•°ï¼šç»Ÿä¸€æ¸²æŸ“å¡ç‰‡ (ä¿æŒ UI é£æ ¼ä¸€è‡´)
# ==========================================
def render_paper_card(paper, is_favorite_mode=False, api_key=None, base_url=None, model_name=None):
    """
    æ¸²æŸ“å•ä¸ªè®ºæ–‡å¡ç‰‡ï¼Œå¤ç”¨äºæœç´¢é¡µå’Œæ”¶è—é¡µã€‚
    """
    # ç»Ÿä¸€æ•°æ®æ ¼å¼
    if isinstance(paper, dict):
        # æ”¶è—é¡µçš„æ•°æ®æ˜¯å­—å…¸
        title = paper['title']
        entry_id = paper['entry_id']
        pdf_url = paper['pdf_url']
        published_date = paper['published']
        authors_list = paper['authors']
        summary_text = paper['summary']
    else:
        # æœç´¢é¡µçš„æ•°æ®æ˜¯ arxiv.Result å¯¹è±¡
        title = paper.title
        entry_id = paper.entry_id
        pdf_url = paper.pdf_url
        published_date = paper.published.strftime('%Y-%m-%d')
        authors_list = [a.name for a in paper.authors]
        summary_text = paper.summary
    
    # --- UI æ¸²æŸ“ ---
    with st.container():
        col1, col2 = st.columns([0.85, 0.15])
        
        with col1:
            st.subheader(title)
            author_str = ", ".join(authors_list[:3]) + (" et al." if len(authors_list) > 3 else "")
            
            # é“¾æ¥
            html_link = f"https://arxiv.org/html/{entry_id.split('/')[-1]}"
            st.markdown(f"**âœï¸ ä½œè€…:** {author_str} | **ğŸ“… å‘å¸ƒ:** {published_date}")
            st.markdown(f"[HTML é˜…è¯»]({html_link}) | [PDF ä¸‹è½½]({pdf_url}) | [ArXiv é¡µé¢]({entry_id})")
        
        with col2:
            # 1. AI è§£è¯»æŒ‰é’®
            ai_btn_key = f"ai_{entry_id}_{'fav' if is_favorite_mode else 'search'}"
            if st.button("ğŸ¤– AI è§£è¯»", key=ai_btn_key):
                status = st.empty()
                status.info("â³ è·å–æ­£æ–‡...")
                content, src = paper_reader.get_paper_content(entry_id, pdf_url)
                if content.startswith("Error"):
                    status.error("âŒ è·å–å¤±è´¥")
                else:
                    status.info(f"âœ… æ­£åœ¨é˜…è¯» ({src})...")
                    summary = ai_agent.get_ai_summary(content, title, api_key, base_url, model_name)
                    st.session_state.summaries[entry_id] = summary
                    status.empty()
            
            # 2. æ”¶è—/ç§»é™¤æŒ‰é’®
            if is_favorite_mode:
                if st.button("âŒ ç§»é™¤", key=f"del_{entry_id}"):
                    storage.remove_favorite(entry_id)
            else:
                if st.button("â¤ï¸ æ”¶è—", key=f"fav_{entry_id}"):
                    storage.save_favorite(paper)
        
        # å±•ç¤º AI ç»“æœ
        if entry_id in st.session_state.summaries:
            st.markdown("#### ğŸ“ AI æ·±åº¦åˆ†æ")
            st.info(st.session_state.summaries[entry_id])
        
        with st.expander("ğŸ“– æ‘˜è¦ (Abstract)"):
            st.write(summary_text)
        
        st.divider()


# ==========================================
# é¡µé¢ 1: ğŸ” è®ºæ–‡æœç´¢ (è¿˜åŸä½ çš„ç»å…¸ç•Œé¢)
# ==========================================
if mode == "ğŸ” è®ºæ–‡æœç´¢":
    # --- ä¾§è¾¹æ ï¼šæœç´¢è®¾ç½® (ä»…åœ¨æœç´¢æ¨¡å¼æ˜¾ç¤º) ---
    st.sidebar.header("ğŸ” æœç´¢è®¾ç½®")
    
    # é¢„è®¾ä¸å…³é”®è¯
    search_presets = {
        "1. AI + Economics":
            '(Economic OR Economics OR Finance OR Financial OR Market OR "Behavioral Economics") AND (LLM OR "Large Language Model" OR RL OR "Reinforcement Learning")',
        "2. Agents (Multi-Agent / LLM Agent)":
            '("Multi-Agent" OR "Multiagent" OR "Autonomous Agent" OR "LLM Agent" OR "Language Agent" OR "RL Agent" OR "Agentic") AND (LLM OR "Large Language Model" OR RL OR "Reinforcement Learning")',
        "3. World Models":
            '"World Model" OR "World Models" OR "Generative World Model" OR "Model-Based RL" OR MBRL OR "Predictive Model"',
        "4. Evolution":
        'agent AND LLM AND (evolution OR evole)',
        "5. è‡ªå®šä¹‰ (ç©ºç™½)": ""
    }
    selected_preset_key = st.sidebar.selectbox("å¿«é€Ÿé€‰æ‹©é¢„è®¾", options=list(search_presets.keys()), index=0)
    default_keyword = search_presets[selected_preset_key]
    
    keywords = st.sidebar.text_input("å…³é”®è¯", value=default_keyword)
    category_bundle = st.sidebar.selectbox("é€‰æ‹©æœç´¢èŒƒå›´", options=list(utils.CATEGORY_QUERIES.keys()), index=0)
    days_back = st.sidebar.slider("æœç´¢è¿‡å»å¤šå°‘å¤©?", min_value=1, max_value=365, value=7)
    max_results = st.sidebar.number_input("æœ€å¤§ç»“æœæ•°é‡", min_value=5, max_value=100, value=20)
    
    st.sidebar.divider()
    st.sidebar.header("ğŸ¤– AI è®¾ç½®")
    env_api_key = os.getenv("OPENAI_API_KEY", "")
    api_key = st.sidebar.text_input("API Key", value=env_api_key, type="password")
    base_url = st.sidebar.text_input("Base URL", value="https://api.openai.com/v1")
    model_name = st.sidebar.text_input("æ¨¡å‹åç§°", value="gpt-4o-mini")
    
    # --- ä¸»ç•Œé¢ UI (è¿˜åŸç»å…¸é£æ ¼) ---
    st.title("ğŸ“‘ ArXiv Paper Daily Tracker")
    # è¿˜åŸä½ æƒ³è¦çš„å°å­—å±•ç¤º
    st.caption(f"å½“å‰æ¨¡å¼: {category_bundle} | çª—å£: {days_back}å¤©")
    
    # è¿˜åŸâ€œå¼€å§‹æŠ“å–â€æŒ‰é’®æ–‡æ¡ˆ
    if st.button("å¼€å§‹æŠ“å–", type="primary"):
        if not keywords:
            st.warning("è¯·è¾“å…¥å…³é”®è¯ï¼")
        else:
            with st.spinner('æ­£åœ¨è¿æ¥ ArXiv æ•°æ®åº“...'):
                query_string = utils.build_query(keywords, category_bundle)
                papers = arxiv_api.fetch_arxiv_papers(query_string, days_back, max_results)
                
                if not papers:
                    st.info("æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è®ºæ–‡ï¼Œè¯·å°è¯•æ”¾å®½æ—¶é—´æˆ–æ›´æ¢å…³é”®è¯ã€‚")
                else:
                    st.session_state.papers = papers
                    st.session_state.summaries = {}
                    st.success(f"æˆåŠŸæ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡ï¼")
    
    # å±•ç¤ºç»“æœ
    if st.session_state.papers:
        st.divider()
        for paper in st.session_state.papers:
            render_paper_card(paper, is_favorite_mode=False, api_key=api_key, base_url=base_url, model_name=model_name)
        
        # å¯¼å‡ºåŠŸèƒ½
        st.header("ğŸ“¤ å¯¼å‡ºç»“æœ")
        if st.button("ç”Ÿæˆ Markdown æŠ¥å‘Š"):
            export_text = utils.generate_export_text(st.session_state.papers, keywords)
            st.download_button("ä¸‹è½½æ–‡ä»¶", export_text, f"arxiv_report_{datetime.date.today()}.md")

# ==========================================
# é¡µé¢ 2: â­ æˆ‘çš„æ”¶è— (æ–°åŠŸèƒ½)
# ==========================================
elif mode == "â­ æˆ‘çš„æ”¶è—":
    st.title("â­ æˆ‘çš„è®ºæ–‡æ”¶è—å¤¹")
    
    # æ”¶è—é¡µä¹Ÿéœ€è¦ AI è®¾ç½®ï¼Œä»¥ä¾¿åœ¨è¿™é‡Œç›´æ¥è§£è¯»
    st.sidebar.header("ğŸ¤– AI è®¾ç½®")
    env_api_key = os.getenv("OPENAI_API_KEY", "")
    api_key = st.sidebar.text_input("API Key", value=env_api_key, type="password")
    base_url = st.sidebar.text_input("Base URL", value="https://api.openai.com/v1")
    model_name = st.sidebar.text_input("æ¨¡å‹åç§°", value="gpt-4o-mini")
    
    favorites = storage.load_favorites()
    
    if not favorites:
        st.info("è¿˜æ²¡æœ‰æ”¶è—ä»»ä½•è®ºæ–‡ã€‚å»æœç´¢é¡µç‚¹ä¸ª â¤ï¸ å§ï¼")
    else:
        st.markdown(f"å…±æ”¶è—äº† **{len(favorites)}** ç¯‡ä¼˜è´¨è®ºæ–‡")
        st.divider()
        
        for paper_dict in favorites:
            render_paper_card(paper_dict, is_favorite_mode=True, api_key=api_key, base_url=base_url,
                              model_name=model_name)